{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8e1e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pickle\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "os.chdir('./../..')\n",
    "\n",
    "def constructData(file, dataset, count):\n",
    "    with open(file, 'r', encoding=\"utf8\") as f:\n",
    "        data = pd.read_csv(f, delimiter=';')\n",
    "        \n",
    "        for ind in data.index:\n",
    "#             print(data['mainline'][ind], '\\n')\n",
    "            dataset[count] = {}\n",
    "            dataset[count]['mainline'] = data['mainline'][ind]\n",
    "            dataset[count]['variant'] = data['variant'][ind]\n",
    "            dataset[count]['language'] = data['language'][ind]\n",
    "#             dataset[count]['fork_date'] = data['fork_date'][ind]\n",
    "            dataset[count]['divergency_date'] = data['divergency_date'][ind]\n",
    "            dataset[count]['least_date'] = data['least_date'][ind]\n",
    "            dataset[count]['pr_patch_ml_no'] = data['pr_patch_ml_no'][ind]\n",
    "            dataset[count]['pr_patch_fv_no'] = data['pr_patch_fv_no'][ind]\n",
    "            dataset[count]['pr_patch_ml_text'] = data['pr_patch_ml_text'][ind]\n",
    "            dataset[count]['pr_patch_fv_text'] = data['pr_patch_fv_text'][ind]\n",
    "            dataset[count]['pr_title_ml_str'] = data['pr_title_ml_str'][ind]\n",
    "            dataset[count]['pr_title_fv_str'] = data['pr_title_fv_str'][ind]\n",
    "            count += 1\n",
    "    return (dataset, count)            \n",
    "\n",
    "\n",
    "def sortAndSaveDatasetBy(datasetFile, sortBy, sortedDatasetFile, asc = False):\n",
    "    with open(datasetFile+'.csv', 'r') as f:\n",
    "        df = pd.read_csv(f)\n",
    "        df = df.sort_values(by=sortBy, ascending=asc)\n",
    "        df.to_csv(sortedDatasetFile+'.csv', sep=';')\n",
    "        \n",
    "    with open(sortedDatasetFile+'.pkl', 'wb') as g:\n",
    "        pickle.dump(df, g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a275130",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a759cd1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = {}\n",
    "count = 0\n",
    "# bugfix = 'New_data/patches_bugfix.csv'\n",
    "opt = 'New_data/patches_optimization.csv'\n",
    "\n",
    "# dataset_bugfix, count_bugfix = constructData(bugfix, dataset, count)\n",
    "dataset_opt, count_opt = constructData(opt, dataset, count)\n",
    "            \n",
    "# with open(\"dataset_bugfix.pkl\", \"wb\") as f:\n",
    "#       pickle.dump(dataset_bugfix,f)\n",
    "\n",
    "with open(\"dataset_opt.pkl\", \"wb\") as f:\n",
    "      pickle.dump(dataset_opt,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a127e3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_list_bugfix = [dataset_bugfix]\n",
    "# new_dataset_bugfix = []\n",
    "# count = 0\n",
    "\n",
    "# for data_item in dataset_list_bugfix:\n",
    "#     for pr in data_item:\n",
    "#         if data_item[pr]['pr_patch_ml_no'] != 0:\n",
    "#             #Add to new dataset\n",
    "#             #Flow mainline to variant\n",
    "#             sub_dataset_ml = {}\n",
    "#             sub_dataset_ml['nr'] = count\n",
    "#             sub_dataset_ml['source'] = data_item[pr]['mainline']\n",
    "#             sub_dataset_ml['destination'] = data_item[pr]['variant']\n",
    "#             sub_dataset_ml['cut_off_date'] = data_item[pr]['least_date']\n",
    "#             sub_dataset_ml['pr_no'] = data_item[pr]['pr_patch_ml_no']\n",
    "#             sub_dataset_ml['pr'] = data_item[pr]['pr_patch_ml_text']\n",
    "#             new_dataset_bugfix.append(sub_dataset_ml)\n",
    "#             count += 1\n",
    "#         if data_item[pr]['pr_patch_fv_no'] != 0:\n",
    "#             #Add to new dataset\n",
    "#             #Flow variant to mainline\n",
    "#             sub_dataset_fv = {}\n",
    "#             sub_dataset_fv['nr'] = count\n",
    "#             sub_dataset_fv['source'] = data_item[pr]['variant']\n",
    "#             sub_dataset_fv['destination'] = data_item[pr]['mainline']\n",
    "#             sub_dataset_fv['cut_off_date'] = data_item[pr]['least_date']\n",
    "#             sub_dataset_fv['pr_no'] = data_item[pr]['pr_patch_fv_no']\n",
    "#             sub_dataset_fv['pr'] = data_item[pr]['pr_patch_fv_text']\n",
    "#             new_dataset_bugfix.append(sub_dataset_fv)\n",
    "#             count += 1\n",
    "            \n",
    "dataset_list_opt = [dataset_opt]\n",
    "new_dataset_opt = []\n",
    "count = 0\n",
    "\n",
    "for data_item in dataset_list_opt:\n",
    "    for pr in data_item:\n",
    "        if data_item[pr]['pr_patch_ml_no'] != 0:\n",
    "            #Add to new dataset\n",
    "            #Flow mainline to variant\n",
    "            sub_dataset_ml = {}\n",
    "            sub_dataset_ml['nr'] = count\n",
    "            sub_dataset_ml['source'] = data_item[pr]['mainline']\n",
    "            sub_dataset_ml['destination'] = data_item[pr]['variant']\n",
    "            sub_dataset_ml['cut_off_date'] = data_item[pr]['least_date']\n",
    "            sub_dataset_ml['pr_no'] = data_item[pr]['pr_patch_ml_no']\n",
    "            sub_dataset_ml['pr'] = data_item[pr]['pr_patch_ml_text']\n",
    "            new_dataset_opt.append(sub_dataset_ml)\n",
    "            count += 1\n",
    "        if data_item[pr]['pr_patch_fv_no'] != 0:\n",
    "            #Add to new dataset\n",
    "            #Flow variant to mainline\n",
    "            sub_dataset_fv = {}\n",
    "            sub_dataset_fv['nr'] = count\n",
    "            sub_dataset_fv['source'] = data_item[pr]['variant']\n",
    "            sub_dataset_fv['destination'] = data_item[pr]['mainline']\n",
    "            sub_dataset_fv['cut_off_date'] = data_item[pr]['least_date']\n",
    "            sub_dataset_fv['pr_no'] = data_item[pr]['pr_patch_fv_no']\n",
    "            sub_dataset_fv['pr'] = data_item[pr]['pr_patch_fv_text']\n",
    "            new_dataset_opt.append(sub_dataset_fv)\n",
    "            count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4638a713",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4741c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('dataset_bugfix.csv', 'w') as f:\n",
    "#     writer = csv.writer(f)\n",
    "#     writer = csv.DictWriter(f, fieldnames=['nr', 'source', 'destination','cut_off_date', 'pr_no', 'pr'])\n",
    "#     writer.writeheader()\n",
    "#     writer.writerows(new_dataset_bugfix)\n",
    "    \n",
    "with open('dataset_opt.csv', 'w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer = csv.DictWriter(f, fieldnames=['nr', 'source', 'destination','cut_off_date', 'pr_no', 'pr'])\n",
    "    writer.writeheader()\n",
    "    writer.writerows(new_dataset_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b860d9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sortAndSaveDatasetBy('dataset_bugfix', 'pr_no', 'sorted_dataset_bugfix')\n",
    "sortAndSaveDatasetBy('dataset_opt', 'pr_no', 'sorted_dataset_opt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786e8389",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count = 0\n",
    "# dataset_pkl ={}\n",
    "# with open('sorted_dataset_bugfix.csv', 'r') as f:\n",
    "#     sorted_data = pd.read_csv(f, delimiter=';')\n",
    "\n",
    "#     for ind in sorted_data.index:\n",
    "#         dataset_pkl[count] = {}\n",
    "#         dataset_pkl[count]['source'] = sorted_data['source'][ind]\n",
    "#         dataset_pkl[count]['destination'] = sorted_data['destination'][ind]\n",
    "#         dataset_pkl[count]['cut_off_date'] = sorted_data['cut_off_date'][ind]\n",
    "#         dataset_pkl[count]['pr_no'] = sorted_data['pr_no'][ind]\n",
    "#         dataset_pkl[count]['pr'] = sorted_data['pr'][ind]\n",
    "#         count += 1\n",
    "\n",
    "# with open('sorted_dataset_bugfix.pkl', 'wb') as f:\n",
    "#     pickle.dump(dataset_pkl, f)\n",
    "    \n",
    "count = 0\n",
    "dataset_pkl ={}\n",
    "with open('sorted_dataset_opt.csv', 'r') as f:\n",
    "    sorted_data = pd.read_csv(f, delimiter=';')\n",
    "\n",
    "    for ind in sorted_data.index:\n",
    "        dataset_pkl[count] = {}\n",
    "        dataset_pkl[count]['source'] = sorted_data['source'][ind]\n",
    "        dataset_pkl[count]['destination'] = sorted_data['destination'][ind]\n",
    "        dataset_pkl[count]['cut_off_date'] = sorted_data['cut_off_date'][ind]\n",
    "        dataset_pkl[count]['pr_no'] = sorted_data['pr_no'][ind]\n",
    "        dataset_pkl[count]['pr'] = sorted_data['pr'][ind]\n",
    "        count += 1\n",
    "\n",
    "with open('sorted_dataset_opt.pkl', 'wb') as f:\n",
    "    pickle.dump(dataset_pkl, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aafec321",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "dataset_pkl ={}\n",
    "with open('sorted_dataset_opt.csv', 'r') as f:\n",
    "    sorted_data = pd.read_csv(f, delimiter=';')\n",
    "\n",
    "    for ind in sorted_data.index:\n",
    "        dataset_pkl[count] = {}\n",
    "        dataset_pkl[count]['source'] = sorted_data['source'][ind]\n",
    "        dataset_pkl[count]['destination'] = sorted_data['destination'][ind]\n",
    "        dataset_pkl[count]['cut_off_date'] = sorted_data['cut_off_date'][ind]\n",
    "        dataset_pkl[count]['pr_no'] = sorted_data['pr_no'][ind]\n",
    "        dataset_pkl[count]['pr'] = sorted_data['pr'][ind]\n",
    "        count += 1\n",
    "\n",
    "with open('sorted_dataset_opt.pkl', 'wb') as f:\n",
    "    pickle.dump(dataset_pkl, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db277e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('sorted_dataset_bugfix.pkl', 'rb') as f:\n",
    "#     data_ = pickle.load(f)\n",
    "#     for i in data_:\n",
    "#         print(i, ' - ' , data_[i]['source'], '-', data_[i]['destination'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1850cf1f",
   "metadata": {},
   "source": [
    "# Other way of reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4a06c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pickle\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "os.chdir('./../..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1cfd83",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('New_data/patches_bugfix.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e73417",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = 9999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33147475",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['pr_patch_ml_no']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43854c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('sorted_dataset_bugFix.pkl', 'rb') as f:\n",
    "    sorted_dataset_bugfix = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbd2a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_dataset_bugfix[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5535b149",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
